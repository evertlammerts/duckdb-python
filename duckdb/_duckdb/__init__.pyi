import collections.abc
import typing

import fsspec
import pandas
import pyarrow.lib
from typing_extensions import Self

import duckdb

from . import functional
from . import typing as duckdb_typing

__all__: list[str] = [
    "BinderException",
    "CSVLineTerminator",
    "CaseExpression",
    "CatalogException",
    "CoalesceOperator",
    "ColumnExpression",
    "ConnectionException",
    "ConstantExpression",
    "ConstraintException",
    "ConversionException",
    "DataError",
    "DatabaseError",
    "DefaultExpression",
    "DependencyException",
    "DuckDBPyConnection",
    "DuckDBPyRelation",
    "Error",
    "ExpectedResultType",
    "ExplainType",
    "Expression",
    "FatalException",
    "FunctionExpression",
    "HTTPException",
    "IOException",
    "IntegrityError",
    "InternalError",
    "InternalException",
    "InterruptException",
    "InvalidInputException",
    "InvalidTypeException",
    "LambdaExpression",
    "NotImplementedException",
    "NotSupportedError",
    "OperationalError",
    "OutOfMemoryException",
    "OutOfRangeException",
    "ParserException",
    "PermissionException",
    "ProgrammingError",
    "PythonExceptionHandling",
    "RenderMode",
    "SQLExpression",
    "SequenceException",
    "SerializationException",
    "StarExpression",
    "Statement",
    "StatementType",
    "SyntaxException",
    "TransactionException",
    "TypeMismatchException",
    "Warning",
    "aggregate",
    "alias",
    "apilevel",
    "append",
    "array_type",
    "arrow",
    "begin",
    "checkpoint",
    "close",
    "commit",
    "connect",
    "create_function",
    "cursor",
    "decimal_type",
    "default_connection",
    "description",
    "df",
    "distinct",
    "dtype",
    "duplicate",
    "enum_type",
    "execute",
    "executemany",
    "extract_statements",
    "fetch_arrow_table",
    "fetch_df",
    "fetch_df_chunk",
    "fetch_record_batch",
    "fetchall",
    "fetchdf",
    "fetchmany",
    "fetchnumpy",
    "fetchone",
    "filesystem_is_registered",
    "filter",
    "from_arrow",
    "from_csv_auto",
    "from_df",
    "from_parquet",
    "from_query",
    "functional",
    "get_table_names",
    "install_extension",
    "interrupt",
    "limit",
    "list_filesystems",
    "list_type",
    "load_extension",
    "map_type",
    "order",
    "paramstyle",
    "pl",
    "project",
    "query",
    "query_df",
    "query_progress",
    "read_csv",
    "read_json",
    "read_parquet",
    "register",
    "register_filesystem",
    "remove_function",
    "rollback",
    "row_type",
    "rowcount",
    "set_default_connection",
    "sql",
    "sqltype",
    "string_type",
    "struct_type",
    "table",
    "table_function",
    "tf",
    "threadsafety",
    "token_type",
    "tokenize",
    "torch",
    "type",
    "typing",
    "union_type",
    "unregister",
    "unregister_filesystem",
    "values",
    "view",
    "write_csv",
]

class BinderException(ProgrammingError): ...

class CSVLineTerminator:
    CARRIAGE_RETURN_LINE_FEED: typing.ClassVar[
        CSVLineTerminator
    ]  # value = <CSVLineTerminator.CARRIAGE_RETURN_LINE_FEED: 1>
    LINE_FEED: typing.ClassVar[CSVLineTerminator]  # value = <CSVLineTerminator.LINE_FEED: 0>
    __members__: typing.ClassVar[
        dict[str, CSVLineTerminator]
    ]  # value = {'LINE_FEED': <CSVLineTerminator.LINE_FEED: 0>, 'CARRIAGE_RETURN_LINE_FEED': <CSVLineTerminator.CARRIAGE_RETURN_LINE_FEED: 1>}  # noqa: E501
    def __eq__(self, other: object) -> bool: ...
    def __getstate__(self) -> int: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __init__(self, value: typing.SupportsInt) -> None: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    def __setstate__(self, state: typing.SupportsInt) -> None: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

class CatalogException(ProgrammingError): ...
class ConnectionException(OperationalError): ...
class ConstraintException(IntegrityError): ...
class ConversionException(DataError): ...
class DataError(DatabaseError): ...
class DatabaseError(Error): ...
class DependencyException(DatabaseError): ...

class DuckDBPyConnection:
    def __del__(self) -> None: ...
    def __enter__(self) -> Self: ...
    def __exit__(self, exc_type: object, exc: object, traceback: object) -> None: ...
    def append(self, table_name: str, df: pandas.DataFrame, *, by_name: bool = False) -> DuckDBPyConnection: ...
    def array_type(self, type: duckdb_typing.DuckDBPyType, size: typing.SupportsInt) -> duckdb_typing.DuckDBPyType: ...
    def arrow(self, rows_per_batch: typing.SupportsInt = 1000000) -> pyarrow.lib.RecordBatchReader: ...
    def begin(self) -> DuckDBPyConnection: ...
    def checkpoint(self) -> DuckDBPyConnection: ...
    def close(self) -> None: ...
    def commit(self) -> DuckDBPyConnection: ...
    def create_function(
        self,
        name: str,
        function: collections.abc.Callable,
        parameters: typing.Any = None,  # noqa: ANN401
        return_type: duckdb_typing.DuckDBPyType | None = None,
        *,
        type: functional.PythonUDFType = ...,
        null_handling: functional.FunctionNullHandling = ...,
        exception_handling: PythonExceptionHandling = ...,
        side_effects: bool = False,
    ) -> DuckDBPyConnection: ...
    def cursor(self) -> DuckDBPyConnection: ...
    def decimal_type(self, width: typing.SupportsInt, scale: typing.SupportsInt) -> duckdb_typing.DuckDBPyType: ...
    def df(self, *, date_as_object: bool = False) -> pandas.DataFrame: ...
    def dtype(self, type_str: str) -> duckdb_typing.DuckDBPyType: ...
    def duplicate(self) -> DuckDBPyConnection: ...
    def enum_type(self, name: str, type: duckdb_typing.DuckDBPyType, values: list) -> duckdb_typing.DuckDBPyType: ...
    def execute(self, query: typing.Any, parameters: typing.Any = None) -> DuckDBPyConnection: ...  # noqa: ANN401
    def executemany(self, query: typing.Any, parameters: typing.Any = None) -> DuckDBPyConnection: ...  # noqa: ANN401
    def extract_statements(self, query: str) -> list: ...
    def fetch_arrow_table(self, rows_per_batch: typing.SupportsInt = 1000000) -> pyarrow.lib.Table: ...
    def fetch_df(self, *, date_as_object: bool = False) -> pandas.DataFrame: ...
    def fetch_df_chunk(
        self, vectors_per_chunk: typing.SupportsInt = 1, *, date_as_object: bool = False
    ) -> pandas.DataFrame: ...
    def fetch_record_batch(self, rows_per_batch: typing.SupportsInt = 1000000) -> pyarrow.lib.RecordBatchReader: ...
    def fetchall(self) -> list: ...
    def fetchdf(self, *, date_as_object: bool = False) -> pandas.DataFrame: ...
    def fetchmany(self, size: typing.SupportsInt = 1) -> list: ...
    def fetchnumpy(self) -> dict: ...
    def fetchone(self) -> tuple | None: ...
    def filesystem_is_registered(self, name: str) -> bool: ...
    def from_arrow(self, arrow_object: typing.Any) -> DuckDBPyRelation: ...  # noqa: ANN401
    def from_csv_auto(self, path_or_buffer: typing.Any, **kwargs) -> DuckDBPyRelation: ...  # noqa: ANN401
    def from_df(self, df: pandas.DataFrame) -> DuckDBPyRelation: ...
    @typing.overload
    def from_parquet(
        self,
        file_glob: str,
        binary_as_string: bool = False,
        *,
        file_row_number: bool = False,
        filename: bool = False,
        hive_partitioning: bool = False,
        union_by_name: bool = False,
        compression: typing.Any = None,  # noqa: ANN401
    ) -> DuckDBPyRelation: ...
    def from_parquet(
        self,
        file_globs: collections.abc.Sequence[str],
        binary_as_string: bool = False,
        *,
        file_row_number: bool = False,
        filename: bool = False,
        hive_partitioning: bool = False,
        union_by_name: bool = False,
        compression: typing.Any = None,
    ) -> DuckDBPyRelation: ...
    def from_query(self, query: typing.Any, *, alias: str = "", params: typing.Any = None) -> DuckDBPyRelation: ...  # noqa: ANN401
    def get_table_names(self, query: str, *, qualified: bool = False) -> set[str]: ...
    def install_extension(
        self,
        extension: str,
        *,
        force_install: bool = False,
        repository: typing.Any = None,  # noqa: ANN401
        repository_url: typing.Any = None,  # noqa: ANN401
        version: typing.Any = None,  # noqa: ANN401
    ) -> None: ...
    def interrupt(self) -> None: ...
    def list_filesystems(self) -> list: ...
    def list_type(self, type: duckdb_typing.DuckDBPyType) -> duckdb_typing.DuckDBPyType: ...
    def load_extension(self, extension: str) -> None: ...
    def map_type(
        self, key: duckdb_typing.DuckDBPyType, value: duckdb_typing.DuckDBPyType
    ) -> duckdb_typing.DuckDBPyType: ...
    def pl(self, rows_per_batch: typing.SupportsInt = 1000000, *, lazy: bool = False) -> ...: ...
    def query(self, query: typing.Any, *, alias: str = "", params: typing.Any = None) -> DuckDBPyRelation: ...  # noqa: ANN401
    def query_progress(self) -> float: ...
    def read_csv(self, path_or_buffer: typing.Any, **kwargs) -> DuckDBPyRelation: ...  # noqa: ANN401
    def read_json(
        self,
        path_or_buffer: typing.Any,  # noqa: ANN401
        *,
        columns: typing.Any | None = None,  # noqa: ANN401
        sample_size: typing.Any | None = None,  # noqa: ANN401
        maximum_depth: typing.Any | None = None,  # noqa: ANN401
        records: str | None = None,
        format: str | None = None,
        date_format: typing.Any | None = None,  # noqa: ANN401
        timestamp_format: typing.Any | None = None,  # noqa: ANN401
        compression: typing.Any | None = None,  # noqa: ANN401
        maximum_object_size: typing.Any | None = None,  # noqa: ANN401
        ignore_errors: typing.Any | None = None,  # noqa: ANN401
        convert_strings_to_integers: typing.Any | None = None,  # noqa: ANN401
        field_appearance_threshold: typing.Any | None = None,  # noqa: ANN401
        map_inference_threshold: typing.Any | None = None,  # noqa: ANN401
        maximum_sample_files: typing.Any | None = None,  # noqa: ANN401
        filename: typing.Any | None = None,  # noqa: ANN401
        hive_partitioning: typing.Any | None = None,  # noqa: ANN401
        union_by_name: typing.Any | None = None,  # noqa: ANN401
        hive_types: typing.Any | None = None,  # noqa: ANN401
        hive_types_autocast: typing.Any | None = None,  # noqa: ANN401
    ) -> DuckDBPyRelation: ...
    @typing.overload
    def read_parquet(
        self,
        file_glob: str,
        binary_as_string: bool = False,
        *,
        file_row_number: bool = False,
        filename: bool = False,
        hive_partitioning: bool = False,
        union_by_name: bool = False,
        compression: typing.Any = None,  # noqa: ANN401
    ) -> DuckDBPyRelation: ...
    def read_parquet(
        self,
        file_globs: collections.abc.Sequence[str],
        binary_as_string: bool = False,
        *,
        file_row_number: bool = False,
        filename: bool = False,
        hive_partitioning: bool = False,
        union_by_name: bool = False,
        compression: typing.Any = None,
    ) -> DuckDBPyRelation: ...
    def register(self, view_name: str, python_object: typing.Any) -> DuckDBPyConnection: ...  # noqa: ANN401
    def register_filesystem(self, filesystem: fsspec.AbstractFileSystem) -> None: ...
    def remove_function(self, name: str) -> DuckDBPyConnection: ...
    def rollback(self) -> DuckDBPyConnection: ...
    def row_type(self, fields: typing.Any) -> duckdb_typing.DuckDBPyType: ...  # noqa: ANN401
    def sql(self, query: typing.Any, *, alias: str = "", params: typing.Any = None) -> DuckDBPyRelation: ...  # noqa: ANN401
    def sqltype(self, type_str: str) -> duckdb_typing.DuckDBPyType: ...
    def string_type(self, collation: str = "") -> duckdb_typing.DuckDBPyType: ...
    def struct_type(self, fields: typing.Any) -> duckdb_typing.DuckDBPyType: ...  # noqa: ANN401
    def table(self, table_name: str) -> DuckDBPyRelation: ...
    def table_function(self, name: str, parameters: typing.Any = None) -> DuckDBPyRelation: ...  # noqa: ANN401
    def tf(self) -> dict: ...
    def torch(self) -> dict: ...
    def type(self, type_str: str) -> duckdb_typing.DuckDBPyType: ...
    def union_type(self, members: typing.Any) -> duckdb_typing.DuckDBPyType: ...  # noqa: ANN401
    def unregister(self, view_name: str) -> DuckDBPyConnection: ...
    def unregister_filesystem(self, name: str) -> None: ...
    def values(self, *args) -> DuckDBPyRelation: ...
    def view(self, view_name: str) -> DuckDBPyRelation: ...
    @property
    def description(self) -> list | None: ...
    @property
    def rowcount(self) -> int: ...

class DuckDBPyRelation:
    def __arrow_c_stream__(self, requested_schema: typing.Any = None) -> typing.Any: ...  # noqa: ANN401
    def __contains__(self, name: str) -> bool: ...
    def __getattr__(self, name: str) -> DuckDBPyRelation: ...
    def __getitem__(self, name: str) -> DuckDBPyRelation: ...
    def __len__(self) -> int: ...
    def aggregate(self, aggr_expr: typing.Any, group_expr: str = "") -> DuckDBPyRelation: ...  # noqa: ANN401
    def any_value(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def apply(
        self,
        function_name: str,
        function_aggr: str,
        group_expr: str = "",
        function_parameter: str = "",
        projected_columns: str = "",
    ) -> DuckDBPyRelation: ...
    def arg_max(
        self, arg_column: str, value_column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def arg_min(
        self, arg_column: str, value_column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def arrow(self, batch_size: typing.SupportsInt = 1000000) -> pyarrow.lib.RecordBatchReader: ...
    def avg(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def bit_and(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def bit_or(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def bit_xor(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def bitstring_agg(
        self,
        column: str,
        min: typing.Any | None = None,  # noqa: ANN401
        max: typing.Any | None = None,  # noqa: ANN401
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> DuckDBPyRelation: ...
    def bool_and(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def bool_or(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def close(self) -> None: ...
    def count(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def create(self, table_name: str) -> None: ...
    def create_view(self, view_name: str, replace: bool = True) -> DuckDBPyRelation: ...
    def cross(self, other_rel: DuckDBPyRelation) -> DuckDBPyRelation: ...
    def cume_dist(self, window_spec: str, projected_columns: str = "") -> DuckDBPyRelation: ...
    def dense_rank(self, window_spec: str, projected_columns: str = "") -> DuckDBPyRelation: ...
    def describe(self) -> DuckDBPyRelation: ...
    def df(self, *, date_as_object: bool = False) -> pandas.DataFrame: ...
    def distinct(self) -> DuckDBPyRelation: ...
    def except_(self, other_rel: DuckDBPyRelation) -> DuckDBPyRelation: ...
    def execute(self) -> DuckDBPyRelation: ...
    def explain(self, type: ExplainType = "standard") -> str: ...
    def favg(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def fetch_arrow_reader(self, batch_size: typing.SupportsInt = 1000000) -> pyarrow.lib.RecordBatchReader: ...
    def fetch_arrow_table(self, batch_size: typing.SupportsInt = 1000000) -> pyarrow.lib.Table: ...
    def fetch_df_chunk(
        self, vectors_per_chunk: typing.SupportsInt = 1, *, date_as_object: bool = False
    ) -> pandas.DataFrame: ...
    def fetch_record_batch(self, rows_per_batch: typing.SupportsInt = 1000000) -> pyarrow.lib.RecordBatchReader: ...
    def fetchall(self) -> list: ...
    def fetchdf(self, *, date_as_object: bool = False) -> pandas.DataFrame: ...
    def fetchmany(self, size: typing.SupportsInt = 1) -> list: ...
    def fetchnumpy(self) -> dict: ...
    def fetchone(self) -> tuple | None: ...
    def filter(self, filter_expr: typing.Any) -> DuckDBPyRelation: ...  # noqa: ANN401
    def first(self, column: str, groups: str = "", projected_columns: str = "") -> DuckDBPyRelation: ...
    def first_value(self, column: str, window_spec: str = "", projected_columns: str = "") -> DuckDBPyRelation: ...
    def fsum(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def geomean(self, column: str, groups: str = "", projected_columns: str = "") -> DuckDBPyRelation: ...
    def histogram(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def insert(self, values: typing.Any) -> None: ...  # noqa: ANN401
    def insert_into(self, table_name: str) -> None: ...
    def intersect(self, other_rel: DuckDBPyRelation) -> DuckDBPyRelation: ...
    def join(self, other_rel: DuckDBPyRelation, condition: typing.Any, how: str = "inner") -> DuckDBPyRelation: ...  # noqa: ANN401
    def lag(
        self,
        column: str,
        window_spec: str,
        offset: typing.SupportsInt = 1,
        default_value: str = "NULL",
        ignore_nulls: bool = False,
        projected_columns: str = "",
    ) -> DuckDBPyRelation: ...
    def last(self, column: str, groups: str = "", projected_columns: str = "") -> DuckDBPyRelation: ...
    def last_value(self, column: str, window_spec: str = "", projected_columns: str = "") -> DuckDBPyRelation: ...
    def lead(
        self,
        column: str,
        window_spec: str,
        offset: typing.SupportsInt = 1,
        default_value: str = "NULL",
        ignore_nulls: bool = False,
        projected_columns: str = "",
    ) -> DuckDBPyRelation: ...
    def limit(self, n: typing.SupportsInt, offset: typing.SupportsInt = 0) -> DuckDBPyRelation: ...
    def list(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def map(self, map_function: collections.abc.Callable, *, schema: typing.Any | None = None) -> DuckDBPyRelation: ...  # noqa: ANN401
    def max(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def mean(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def median(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def min(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def mode(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def n_tile(
        self, window_spec: str, num_buckets: typing.SupportsInt, projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def nth_value(
        self,
        column: str,
        window_spec: str,
        offset: typing.SupportsInt,
        ignore_nulls: bool = False,
        projected_columns: str = "",
    ) -> DuckDBPyRelation: ...
    def order(self, order_expr: str) -> DuckDBPyRelation: ...
    def percent_rank(self, window_spec: str, projected_columns: str = "") -> DuckDBPyRelation: ...
    def pl(self, batch_size: typing.SupportsInt = 1000000, *, lazy: bool = False) -> ...: ...
    def product(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def project(self, *args, groups: str = "") -> DuckDBPyRelation: ...
    def quantile(
        self,
        column: str,
        q: typing.Any = 0.5,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",  # noqa: ANN401
    ) -> DuckDBPyRelation: ...
    def quantile_cont(
        self,
        column: str,
        q: typing.Any = 0.5,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",  # noqa: ANN401
    ) -> DuckDBPyRelation: ...
    def quantile_disc(
        self,
        column: str,
        q: typing.Any = 0.5,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",  # noqa: ANN401
    ) -> DuckDBPyRelation: ...
    def query(self, virtual_table_name: str, sql_query: str) -> DuckDBPyRelation: ...
    def rank(self, window_spec: str, projected_columns: str = "") -> DuckDBPyRelation: ...
    def rank_dense(self, window_spec: str, projected_columns: str = "") -> DuckDBPyRelation: ...
    def record_batch(self, batch_size: typing.SupportsInt = 1000000) -> typing.Any: ...  # noqa: ANN401
    def row_number(self, window_spec: str, projected_columns: str = "") -> DuckDBPyRelation: ...
    def select(self, *args, groups: str = "") -> DuckDBPyRelation: ...
    def select_dtypes(self, types: typing.Any) -> DuckDBPyRelation: ...  # noqa: ANN401
    def select_types(self, types: typing.Any) -> DuckDBPyRelation: ...  # noqa: ANN401
    def set_alias(self, alias: str) -> DuckDBPyRelation: ...
    def show(
        self,
        *,
        max_width: typing.SupportsInt | None = None,
        max_rows: typing.SupportsInt | None = None,
        max_col_width: typing.SupportsInt | None = None,
        null_value: str | None = None,
        render_mode: typing.Any = None,  # noqa: ANN401
    ) -> None: ...
    def sort(self, *args) -> DuckDBPyRelation: ...
    def sql_query(self) -> str: ...
    def std(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def stddev(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def stddev_pop(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def stddev_samp(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def string_agg(
        self, column: str, sep: str = ",", groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def sum(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def tf(self) -> dict: ...
    def to_arrow_table(self, batch_size: typing.SupportsInt = 1000000) -> pyarrow.lib.Table: ...
    def to_csv(
        self,
        file_name: str,
        *,
        sep: typing.Any = None,  # noqa: ANN401
        na_rep: typing.Any = None,  # noqa: ANN401
        header: typing.Any = None,  # noqa: ANN401
        quotechar: typing.Any = None,  # noqa: ANN401
        escapechar: typing.Any = None,  # noqa: ANN401
        date_format: typing.Any = None,  # noqa: ANN401
        timestamp_format: typing.Any = None,  # noqa: ANN401
        quoting: typing.Any = None,  # noqa: ANN401
        encoding: typing.Any = None,  # noqa: ANN401
        compression: typing.Any = None,  # noqa: ANN401
        overwrite: typing.Any = None,  # noqa: ANN401
        per_thread_output: typing.Any = None,  # noqa: ANN401
        use_tmp_file: typing.Any = None,  # noqa: ANN401
        partition_by: typing.Any = None,  # noqa: ANN401
        write_partition_columns: typing.Any = None,  # noqa: ANN401
    ) -> None: ...
    def to_df(self, *, date_as_object: bool = False) -> pandas.DataFrame: ...
    def to_parquet(
        self,
        file_name: str,
        *,
        compression: typing.Any = None,  # noqa: ANN401
        field_ids: typing.Any = None,  # noqa: ANN401
        row_group_size_bytes: typing.Any = None,  # noqa: ANN401
        row_group_size: typing.Any = None,  # noqa: ANN401
        overwrite: typing.Any = None,  # noqa: ANN401
        per_thread_output: typing.Any = None,  # noqa: ANN401
        use_tmp_file: typing.Any = None,  # noqa: ANN401
        partition_by: typing.Any = None,  # noqa: ANN401
        write_partition_columns: typing.Any = None,  # noqa: ANN401
        append: typing.Any = None,  # noqa: ANN401
    ) -> None: ...
    def to_table(self, table_name: str) -> None: ...
    def to_view(self, view_name: str, replace: bool = True) -> DuckDBPyRelation: ...
    def torch(self) -> dict: ...
    def union(self, union_rel: DuckDBPyRelation) -> DuckDBPyRelation: ...
    def unique(self, unique_aggr: str) -> DuckDBPyRelation: ...
    def update(self, set: typing.Any, *, condition: typing.Any = None) -> None: ...  # noqa: ANN401
    def value_counts(self, column: str, groups: str = "") -> DuckDBPyRelation: ...
    def var(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def var_pop(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def var_samp(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def variance(
        self, column: str, groups: str = "", window_spec: str = "", projected_columns: str = ""
    ) -> DuckDBPyRelation: ...
    def write_csv(
        self,
        file_name: str,
        *,
        sep: typing.Any = None,  # noqa: ANN401
        na_rep: typing.Any = None,  # noqa: ANN401
        header: typing.Any = None,  # noqa: ANN401
        quotechar: typing.Any = None,  # noqa: ANN401
        escapechar: typing.Any = None,  # noqa: ANN401
        date_format: typing.Any = None,  # noqa: ANN401
        timestamp_format: typing.Any = None,  # noqa: ANN401
        quoting: typing.Any = None,  # noqa: ANN401
        encoding: typing.Any = None,  # noqa: ANN401
        compression: typing.Any = None,  # noqa: ANN401
        overwrite: typing.Any = None,  # noqa: ANN401
        per_thread_output: typing.Any = None,  # noqa: ANN401
        use_tmp_file: typing.Any = None,  # noqa: ANN401
        partition_by: typing.Any = None,  # noqa: ANN401
        write_partition_columns: typing.Any = None,  # noqa: ANN401
    ) -> None: ...
    def write_parquet(
        self,
        file_name: str,
        *,
        compression: typing.Any = None,  # noqa: ANN401
        field_ids: typing.Any = None,  # noqa: ANN401
        row_group_size_bytes: typing.Any = None,  # noqa: ANN401
        row_group_size: typing.Any = None,  # noqa: ANN401
        overwrite: typing.Any = None,  # noqa: ANN401
        per_thread_output: typing.Any = None,  # noqa: ANN401
        use_tmp_file: typing.Any = None,  # noqa: ANN401
        partition_by: typing.Any = None,  # noqa: ANN401
        write_partition_columns: typing.Any = None,  # noqa: ANN401
        append: typing.Any = None,  # noqa: ANN401
    ) -> None: ...
    @property
    def alias(self) -> str: ...
    @property
    def columns(self) -> list: ...
    @property
    def description(self) -> list: ...
    @property
    def dtypes(self) -> list: ...
    @property
    def shape(self) -> tuple: ...
    @property
    def type(self) -> str: ...
    @property
    def types(self) -> list: ...

class Error(Exception): ...

class ExpectedResultType:
    CHANGED_ROWS: typing.ClassVar[ExpectedResultType]  # value = <ExpectedResultType.CHANGED_ROWS: 1>
    NOTHING: typing.ClassVar[ExpectedResultType]  # value = <ExpectedResultType.NOTHING: 2>
    QUERY_RESULT: typing.ClassVar[ExpectedResultType]  # value = <ExpectedResultType.QUERY_RESULT: 0>
    __members__: typing.ClassVar[
        dict[str, ExpectedResultType]
    ]  # value = {'QUERY_RESULT': <ExpectedResultType.QUERY_RESULT: 0>, 'CHANGED_ROWS': <ExpectedResultType.CHANGED_ROWS: 1>, 'NOTHING': <ExpectedResultType.NOTHING: 2>}  # noqa: E501
    def __eq__(self, other: object) -> bool: ...
    def __getstate__(self) -> int: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __init__(self, value: typing.SupportsInt) -> None: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    def __setstate__(self, state: typing.SupportsInt) -> None: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

class ExplainType:
    ANALYZE: typing.ClassVar[ExplainType]  # value = <ExplainType.ANALYZE: 1>
    STANDARD: typing.ClassVar[ExplainType]  # value = <ExplainType.STANDARD: 0>
    __members__: typing.ClassVar[
        dict[str, ExplainType]
    ]  # value = {'STANDARD': <ExplainType.STANDARD: 0>, 'ANALYZE': <ExplainType.ANALYZE: 1>}
    def __eq__(self, other: object) -> bool: ...
    def __getstate__(self) -> int: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __init__(self, value: typing.SupportsInt) -> None: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    def __setstate__(self, state: typing.SupportsInt) -> None: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

class Expression:
    __hash__: typing.ClassVar[None] = None
    def __add__(self, other: Expression) -> Expression: ...
    def __and__(self, other: Expression) -> Expression: ...
    def __div__(self, other: Expression) -> Expression: ...
    def __eq__(self, other: Expression) -> Expression: ...
    def __floordiv__(self, other: Expression) -> Expression: ...
    def __ge__(self, other: Expression) -> Expression: ...
    def __gt__(self, other: Expression) -> Expression: ...
    @typing.overload
    def __init__(self, arg0: str) -> None: ...
    def __init__(self, arg0: typing.Any) -> None: ...
    def __invert__(self) -> Expression: ...
    def __le__(self, other: Expression) -> Expression: ...
    def __lt__(self, other: Expression) -> Expression: ...
    def __mod__(self, other: Expression) -> Expression: ...
    def __mul__(self, other: Expression) -> Expression: ...
    def __ne__(self, other: Expression) -> Expression: ...
    def __neg__(self) -> Expression: ...
    def __or__(self, other: Expression) -> Expression: ...
    def __pow__(self, other: Expression) -> Expression: ...
    def __radd__(self, other: Expression) -> Expression: ...
    def __rand__(self, other: Expression) -> Expression: ...
    def __rdiv__(self, other: Expression) -> Expression: ...
    def __rfloordiv__(self, other: Expression) -> Expression: ...
    def __rmod__(self, other: Expression) -> Expression: ...
    def __rmul__(self, other: Expression) -> Expression: ...
    def __ror__(self, other: Expression) -> Expression: ...
    def __rpow__(self, other: Expression) -> Expression: ...
    def __rsub__(self, other: Expression) -> Expression: ...
    def __rtruediv__(self, other: Expression) -> Expression: ...
    def __sub__(self, other: Expression) -> Expression: ...
    def __truediv__(self, other: Expression) -> Expression: ...
    def alias(self, name: str) -> Expression: ...
    def asc(self) -> Expression: ...
    def between(self, lower: Expression, upper: Expression) -> Expression: ...
    def cast(self, type: duckdb_typing.DuckDBPyType) -> Expression: ...
    def collate(self, collation: str) -> Expression: ...
    def desc(self) -> Expression: ...
    def get_name(self) -> str: ...
    def isin(self, *args) -> Expression: ...
    def isnotin(self, *args) -> Expression: ...
    def isnotnull(self) -> Expression: ...
    def isnull(self) -> Expression: ...
    def nulls_first(self) -> Expression: ...
    def nulls_last(self) -> Expression: ...
    def otherwise(self, value: Expression) -> Expression: ...
    def show(self) -> None: ...
    def when(self, condition: Expression, value: Expression) -> Expression: ...

class FatalException(DatabaseError): ...
class HTTPException(IOException): ...
class IOException(OperationalError): ...
class IntegrityError(DatabaseError): ...
class InternalError(DatabaseError): ...
class InternalException(InternalError): ...
class InterruptException(DatabaseError): ...
class InvalidInputException(ProgrammingError): ...
class InvalidTypeException(ProgrammingError): ...
class NotImplementedException(NotSupportedError): ...
class NotSupportedError(DatabaseError): ...
class OperationalError(DatabaseError): ...
class OutOfMemoryException(OperationalError): ...
class OutOfRangeException(DataError): ...
class ParserException(ProgrammingError): ...
class PermissionException(DatabaseError): ...
class ProgrammingError(DatabaseError): ...

class PythonExceptionHandling:
    DEFAULT: typing.ClassVar[PythonExceptionHandling]  # value = <PythonExceptionHandling.DEFAULT: 0>
    RETURN_NULL: typing.ClassVar[PythonExceptionHandling]  # value = <PythonExceptionHandling.RETURN_NULL: 1>
    __members__: typing.ClassVar[
        dict[str, PythonExceptionHandling]
    ]  # value = {'DEFAULT': <PythonExceptionHandling.DEFAULT: 0>, 'RETURN_NULL': <PythonExceptionHandling.RETURN_NULL: 1>}  # noqa: E501
    def __eq__(self, other: object) -> bool: ...
    def __getstate__(self) -> int: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __init__(self, value: typing.SupportsInt) -> None: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    def __setstate__(self, state: typing.SupportsInt) -> None: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

class RenderMode:
    COLUMNS: typing.ClassVar[RenderMode]  # value = <RenderMode.COLUMNS: 1>
    ROWS: typing.ClassVar[RenderMode]  # value = <RenderMode.ROWS: 0>
    __members__: typing.ClassVar[
        dict[str, RenderMode]
    ]  # value = {'ROWS': <RenderMode.ROWS: 0>, 'COLUMNS': <RenderMode.COLUMNS: 1>}
    def __eq__(self, other: object) -> bool: ...
    def __getstate__(self) -> int: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __init__(self, value: typing.SupportsInt) -> None: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    def __setstate__(self, state: typing.SupportsInt) -> None: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

class SequenceException(DatabaseError): ...
class SerializationException(OperationalError): ...

class Statement:
    @property
    def expected_result_type(self) -> list: ...
    @property
    def named_parameters(self) -> set: ...
    @property
    def query(self) -> str: ...
    @property
    def type(self) -> StatementType: ...

class StatementType:
    ALTER_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.ALTER_STATEMENT: 8>
    ANALYZE_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.ANALYZE_STATEMENT: 11>
    ATTACH_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.ATTACH_STATEMENT: 25>
    CALL_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.CALL_STATEMENT: 19>
    COPY_DATABASE_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.COPY_DATABASE_STATEMENT: 28>
    COPY_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.COPY_STATEMENT: 10>
    CREATE_FUNC_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.CREATE_FUNC_STATEMENT: 13>
    CREATE_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.CREATE_STATEMENT: 4>
    DELETE_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.DELETE_STATEMENT: 5>
    DETACH_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.DETACH_STATEMENT: 26>
    DROP_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.DROP_STATEMENT: 15>
    EXECUTE_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.EXECUTE_STATEMENT: 7>
    EXPLAIN_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.EXPLAIN_STATEMENT: 14>
    EXPORT_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.EXPORT_STATEMENT: 16>
    EXTENSION_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.EXTENSION_STATEMENT: 23>
    INSERT_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.INSERT_STATEMENT: 2>
    INVALID_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.INVALID_STATEMENT: 0>
    LOAD_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.LOAD_STATEMENT: 21>
    LOGICAL_PLAN_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.LOGICAL_PLAN_STATEMENT: 24>
    MERGE_INTO_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.MERGE_INTO_STATEMENT: 30>
    MULTI_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.MULTI_STATEMENT: 27>
    PRAGMA_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.PRAGMA_STATEMENT: 17>
    PREPARE_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.PREPARE_STATEMENT: 6>
    RELATION_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.RELATION_STATEMENT: 22>
    SELECT_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.SELECT_STATEMENT: 1>
    SET_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.SET_STATEMENT: 20>
    TRANSACTION_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.TRANSACTION_STATEMENT: 9>
    UPDATE_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.UPDATE_STATEMENT: 3>
    VACUUM_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.VACUUM_STATEMENT: 18>
    VARIABLE_SET_STATEMENT: typing.ClassVar[StatementType]  # value = <StatementType.VARIABLE_SET_STATEMENT: 12>
    __members__: typing.ClassVar[
        dict[str, StatementType]
    ]  # value = {'INVALID_STATEMENT': <StatementType.INVALID_STATEMENT: 0>, 'SELECT_STATEMENT': <StatementType.SELECT_STATEMENT: 1>, 'INSERT_STATEMENT': <StatementType.INSERT_STATEMENT: 2>, 'UPDATE_STATEMENT': <StatementType.UPDATE_STATEMENT: 3>, 'CREATE_STATEMENT': <StatementType.CREATE_STATEMENT: 4>, 'DELETE_STATEMENT': <StatementType.DELETE_STATEMENT: 5>, 'PREPARE_STATEMENT': <StatementType.PREPARE_STATEMENT: 6>, 'EXECUTE_STATEMENT': <StatementType.EXECUTE_STATEMENT: 7>, 'ALTER_STATEMENT': <StatementType.ALTER_STATEMENT: 8>, 'TRANSACTION_STATEMENT': <StatementType.TRANSACTION_STATEMENT: 9>, 'COPY_STATEMENT': <StatementType.COPY_STATEMENT: 10>, 'ANALYZE_STATEMENT': <StatementType.ANALYZE_STATEMENT: 11>, 'VARIABLE_SET_STATEMENT': <StatementType.VARIABLE_SET_STATEMENT: 12>, 'CREATE_FUNC_STATEMENT': <StatementType.CREATE_FUNC_STATEMENT: 13>, 'EXPLAIN_STATEMENT': <StatementType.EXPLAIN_STATEMENT: 14>, 'DROP_STATEMENT': <StatementType.DROP_STATEMENT: 15>, 'EXPORT_STATEMENT': <StatementType.EXPORT_STATEMENT: 16>, 'PRAGMA_STATEMENT': <StatementType.PRAGMA_STATEMENT: 17>, 'VACUUM_STATEMENT': <StatementType.VACUUM_STATEMENT: 18>, 'CALL_STATEMENT': <StatementType.CALL_STATEMENT: 19>, 'SET_STATEMENT': <StatementType.SET_STATEMENT: 20>, 'LOAD_STATEMENT': <StatementType.LOAD_STATEMENT: 21>, 'RELATION_STATEMENT': <StatementType.RELATION_STATEMENT: 22>, 'EXTENSION_STATEMENT': <StatementType.EXTENSION_STATEMENT: 23>, 'LOGICAL_PLAN_STATEMENT': <StatementType.LOGICAL_PLAN_STATEMENT: 24>, 'ATTACH_STATEMENT': <StatementType.ATTACH_STATEMENT: 25>, 'DETACH_STATEMENT': <StatementType.DETACH_STATEMENT: 26>, 'MULTI_STATEMENT': <StatementType.MULTI_STATEMENT: 27>, 'COPY_DATABASE_STATEMENT': <StatementType.COPY_DATABASE_STATEMENT: 28>, 'MERGE_INTO_STATEMENT': <StatementType.MERGE_INTO_STATEMENT: 30>}  # noqa: E501
    def __eq__(self, other: object) -> bool: ...
    def __getstate__(self) -> int: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __init__(self, value: typing.SupportsInt) -> None: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    def __setstate__(self, state: typing.SupportsInt) -> None: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

class SyntaxException(ProgrammingError): ...
class TransactionException(OperationalError): ...
class TypeMismatchException(DataError): ...
class Warning(Exception): ...

class token_type:
    __members__: typing.ClassVar[
        dict[str, token_type]
    ]  # value = {'identifier': <token_type.identifier: 0>, 'numeric_const': <token_type.numeric_const: 1>, 'string_const': <token_type.string_const: 2>, 'operator': <token_type.operator: 3>, 'keyword': <token_type.keyword: 4>, 'comment': <token_type.comment: 5>}  # noqa: E501
    comment: typing.ClassVar[token_type]  # value = <token_type.comment: 5>
    identifier: typing.ClassVar[token_type]  # value = <token_type.identifier: 0>
    keyword: typing.ClassVar[token_type]  # value = <token_type.keyword: 4>
    numeric_const: typing.ClassVar[token_type]  # value = <token_type.numeric_const: 1>
    operator: typing.ClassVar[token_type]  # value = <token_type.operator: 3>
    string_const: typing.ClassVar[token_type]  # value = <token_type.string_const: 2>
    def __eq__(self, other: object) -> bool: ...
    def __getstate__(self) -> int: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __init__(self, value: typing.SupportsInt) -> None: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    def __setstate__(self, state: typing.SupportsInt) -> None: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

def CaseExpression(condition: Expression, value: Expression) -> Expression: ...
def CoalesceOperator(*args) -> Expression: ...
def ColumnExpression(*args) -> Expression: ...
def ConstantExpression(value: typing.Any) -> Expression: ...  # noqa: ANN401
def DefaultExpression() -> Expression: ...
def FunctionExpression(function_name: str, *args) -> Expression: ...
def LambdaExpression(lhs: typing.Any, rhs: Expression) -> Expression: ...  # noqa: ANN401
def SQLExpression(expression: str) -> Expression: ...
@typing.overload
def StarExpression(*, exclude: typing.Any = None) -> Expression: ...  # noqa: ANN401
def StarExpression() -> Expression: ...
def aggregate(
    df: pandas.DataFrame,
    aggr_expr: typing.Any,  # noqa: ANN401
    group_expr: str = "",
    *,
    connection: duckdb.DuckDBPyConnection | None = None,
) -> DuckDBPyRelation: ...
def alias(
    df: pandas.DataFrame, alias: str, *, connection: duckdb.DuckDBPyConnection | None = None
) -> DuckDBPyRelation: ...
def append(
    table_name: str, df: pandas.DataFrame, *, by_name: bool = False, connection: duckdb.DuckDBPyConnection | None = None
) -> duckdb.DuckDBPyConnection: ...
def array_type(
    type: duckdb_typing.DuckDBPyType, size: typing.SupportsInt, *, connection: duckdb.DuckDBPyConnection | None = None
) -> duckdb_typing.DuckDBPyType: ...
@typing.overload
def arrow(
    rows_per_batch: typing.SupportsInt = 1000000, *, connection: duckdb.DuckDBPyConnection | None = None
) -> pyarrow.lib.RecordBatchReader: ...
def arrow(arrow_object: typing.Any, *, connection: duckdb.DuckDBPyConnection | None = None) -> DuckDBPyRelation: ...
def begin(*, connection: duckdb.DuckDBPyConnection | None = None) -> duckdb.DuckDBPyConnection: ...
def checkpoint(*, connection: duckdb.DuckDBPyConnection | None = None) -> duckdb.DuckDBPyConnection: ...
def close(*, connection: duckdb.DuckDBPyConnection | None = None) -> None: ...
def commit(*, connection: duckdb.DuckDBPyConnection | None = None) -> duckdb.DuckDBPyConnection: ...
def connect(
    database: typing.Any = ":memory:",
    read_only: bool = False,
    config: dict | None = None,  # noqa: ANN401
) -> duckdb.DuckDBPyConnection: ...
def create_function(
    name: str,
    function: collections.abc.Callable,
    parameters: typing.Any = None,  # noqa: ANN401
    return_type: duckdb_typing.DuckDBPyType | None = None,
    *,
    type: functional.PythonUDFType = ...,
    null_handling: functional.FunctionNullHandling = ...,
    exception_handling: PythonExceptionHandling = ...,
    side_effects: bool = False,
    connection: duckdb.DuckDBPyConnection | None = None,
) -> duckdb.DuckDBPyConnection: ...
def cursor(*, connection: duckdb.DuckDBPyConnection | None = None) -> duckdb.DuckDBPyConnection: ...
def decimal_type(
    width: typing.SupportsInt, scale: typing.SupportsInt, *, connection: duckdb.DuckDBPyConnection | None = None
) -> duckdb_typing.DuckDBPyType: ...
def default_connection() -> duckdb.DuckDBPyConnection: ...
def description(*, connection: duckdb.DuckDBPyConnection | None = None) -> list | None: ...
@typing.overload
def df(*, date_as_object: bool = False, connection: duckdb.DuckDBPyConnection | None = None) -> pandas.DataFrame: ...
def df(df: pandas.DataFrame, *, connection: duckdb.DuckDBPyConnection | None = None) -> DuckDBPyRelation: ...
def distinct(df: pandas.DataFrame, *, connection: duckdb.DuckDBPyConnection | None = None) -> DuckDBPyRelation: ...
def dtype(type_str: str, *, connection: duckdb.DuckDBPyConnection | None = None) -> duckdb_typing.DuckDBPyType: ...
def duplicate(*, connection: duckdb.DuckDBPyConnection | None = None) -> duckdb.DuckDBPyConnection: ...
def enum_type(
    name: str, type: duckdb_typing.DuckDBPyType, values: list, *, connection: duckdb.DuckDBPyConnection | None = None
) -> duckdb_typing.DuckDBPyType: ...
def execute(
    query: typing.Any,
    parameters: typing.Any = None,
    *,
    connection: duckdb.DuckDBPyConnection | None = None,  # noqa: ANN401
) -> duckdb.DuckDBPyConnection: ...
def executemany(
    query: typing.Any,
    parameters: typing.Any = None,
    *,
    connection: duckdb.DuckDBPyConnection | None = None,  # noqa: ANN401
) -> duckdb.DuckDBPyConnection: ...
def extract_statements(query: str, *, connection: duckdb.DuckDBPyConnection | None = None) -> list: ...
def fetch_arrow_table(
    rows_per_batch: typing.SupportsInt = 1000000, *, connection: duckdb.DuckDBPyConnection | None = None
) -> pyarrow.lib.Table: ...
def fetch_df(
    *, date_as_object: bool = False, connection: duckdb.DuckDBPyConnection | None = None
) -> pandas.DataFrame: ...
def fetch_df_chunk(
    vectors_per_chunk: typing.SupportsInt = 1,
    *,
    date_as_object: bool = False,
    connection: duckdb.DuckDBPyConnection | None = None,
) -> pandas.DataFrame: ...
def fetch_record_batch(
    rows_per_batch: typing.SupportsInt = 1000000, *, connection: duckdb.DuckDBPyConnection | None = None
) -> pyarrow.lib.RecordBatchReader: ...
def fetchall(*, connection: duckdb.DuckDBPyConnection | None = None) -> list: ...
def fetchdf(
    *, date_as_object: bool = False, connection: duckdb.DuckDBPyConnection | None = None
) -> pandas.DataFrame: ...
def fetchmany(size: typing.SupportsInt = 1, *, connection: duckdb.DuckDBPyConnection | None = None) -> list: ...
def fetchnumpy(*, connection: duckdb.DuckDBPyConnection | None = None) -> dict: ...
def fetchone(*, connection: duckdb.DuckDBPyConnection | None = None) -> tuple | None: ...
def filesystem_is_registered(name: str, *, connection: duckdb.DuckDBPyConnection | None = None) -> bool: ...
def filter(
    df: pandas.DataFrame,
    filter_expr: typing.Any,
    *,
    connection: duckdb.DuckDBPyConnection | None = None,  # noqa: ANN401
) -> DuckDBPyRelation: ...
def from_arrow(
    arrow_object: typing.Any,
    *,
    connection: duckdb.DuckDBPyConnection | None = None,  # noqa: ANN401
) -> DuckDBPyRelation: ...
def from_csv_auto(path_or_buffer: typing.Any, **kwargs) -> DuckDBPyRelation: ...  # noqa: ANN401
def from_df(df: pandas.DataFrame, *, connection: duckdb.DuckDBPyConnection | None = None) -> DuckDBPyRelation: ...
@typing.overload
def from_parquet(
    file_glob: str,
    binary_as_string: bool = False,
    *,
    file_row_number: bool = False,
    filename: bool = False,
    hive_partitioning: bool = False,
    union_by_name: bool = False,
    compression: typing.Any = None,  # noqa: ANN401
    connection: duckdb.DuckDBPyConnection | None = None,
) -> DuckDBPyRelation: ...
def from_parquet(
    file_globs: collections.abc.Sequence[str],
    binary_as_string: bool = False,
    *,
    file_row_number: bool = False,
    filename: bool = False,
    hive_partitioning: bool = False,
    union_by_name: bool = False,
    compression: typing.Any = None,
    connection: duckdb.DuckDBPyConnection | None = None,
) -> DuckDBPyRelation: ...
def from_query(
    query: typing.Any,  # noqa: ANN401
    *,
    alias: str = "",
    params: typing.Any = None,  # noqa: ANN401
    connection: duckdb.DuckDBPyConnection | None = None,
) -> DuckDBPyRelation: ...
def get_table_names(
    query: str, *, qualified: bool = False, connection: duckdb.DuckDBPyConnection | None = None
) -> set[str]: ...
def install_extension(
    extension: str,
    *,
    force_install: bool = False,
    repository: typing.Any = None,  # noqa: ANN401
    repository_url: typing.Any = None,  # noqa: ANN401
    version: typing.Any = None,  # noqa: ANN401
    connection: duckdb.DuckDBPyConnection | None = None,
) -> None: ...
def interrupt(*, connection: duckdb.DuckDBPyConnection | None = None) -> None: ...
def limit(
    df: pandas.DataFrame,
    n: typing.SupportsInt,
    offset: typing.SupportsInt = 0,
    *,
    connection: duckdb.DuckDBPyConnection | None = None,
) -> DuckDBPyRelation: ...
def list_filesystems(*, connection: duckdb.DuckDBPyConnection | None = None) -> list: ...
def list_type(
    type: duckdb_typing.DuckDBPyType, *, connection: duckdb.DuckDBPyConnection | None = None
) -> duckdb_typing.DuckDBPyType: ...
def load_extension(extension: str, *, connection: duckdb.DuckDBPyConnection | None = None) -> None: ...
def map_type(
    key: duckdb_typing.DuckDBPyType,
    value: duckdb_typing.DuckDBPyType,
    *,
    connection: duckdb.DuckDBPyConnection | None = None,
) -> duckdb_typing.DuckDBPyType: ...
def order(
    df: pandas.DataFrame, order_expr: str, *, connection: duckdb.DuckDBPyConnection | None = None
) -> DuckDBPyRelation: ...
def pl(
    rows_per_batch: typing.SupportsInt = 1000000,
    *,
    lazy: bool = False,
    connection: duckdb.DuckDBPyConnection | None = None,
) -> ...: ...
def project(
    df: pandas.DataFrame, *args, groups: str = "", connection: duckdb.DuckDBPyConnection | None = None
) -> DuckDBPyRelation: ...
def query(
    query: typing.Any,  # noqa: ANN401
    *,
    alias: str = "",
    params: typing.Any = None,  # noqa: ANN401
    connection: duckdb.DuckDBPyConnection | None = None,
) -> DuckDBPyRelation: ...
def query_df(
    df: pandas.DataFrame,
    virtual_table_name: str,
    sql_query: str,
    *,
    connection: duckdb.DuckDBPyConnection | None = None,
) -> DuckDBPyRelation: ...
def query_progress(*, connection: duckdb.DuckDBPyConnection | None = None) -> float: ...
def read_csv(path_or_buffer: typing.Any, **kwargs) -> DuckDBPyRelation: ...  # noqa: ANN401
def read_json(
    path_or_buffer: typing.Any,  # noqa: ANN401
    *,
    columns: typing.Any | None = None,  # noqa: ANN401
    sample_size: typing.Any | None = None,  # noqa: ANN401
    maximum_depth: typing.Any | None = None,  # noqa: ANN401
    records: str | None = None,
    format: str | None = None,
    date_format: typing.Any | None = None,  # noqa: ANN401
    timestamp_format: typing.Any | None = None,  # noqa: ANN401
    compression: typing.Any | None = None,  # noqa: ANN401
    maximum_object_size: typing.Any | None = None,  # noqa: ANN401
    ignore_errors: typing.Any | None = None,  # noqa: ANN401
    convert_strings_to_integers: typing.Any | None = None,  # noqa: ANN401
    field_appearance_threshold: typing.Any | None = None,  # noqa: ANN401
    map_inference_threshold: typing.Any | None = None,  # noqa: ANN401
    maximum_sample_files: typing.Any | None = None,  # noqa: ANN401
    filename: typing.Any | None = None,  # noqa: ANN401
    hive_partitioning: typing.Any | None = None,  # noqa: ANN401
    union_by_name: typing.Any | None = None,  # noqa: ANN401
    hive_types: typing.Any | None = None,  # noqa: ANN401
    hive_types_autocast: typing.Any | None = None,  # noqa: ANN401
    connection: duckdb.DuckDBPyConnection | None = None,
) -> DuckDBPyRelation: ...
@typing.overload
def read_parquet(
    file_glob: str,
    binary_as_string: bool = False,
    *,
    file_row_number: bool = False,
    filename: bool = False,
    hive_partitioning: bool = False,
    union_by_name: bool = False,
    compression: typing.Any = None,  # noqa: ANN401
    connection: duckdb.DuckDBPyConnection | None = None,
) -> DuckDBPyRelation: ...
def read_parquet(
    file_globs: collections.abc.Sequence[str],
    binary_as_string: bool = False,
    *,
    file_row_number: bool = False,
    filename: bool = False,
    hive_partitioning: bool = False,
    union_by_name: bool = False,
    compression: typing.Any = None,
    connection: duckdb.DuckDBPyConnection | None = None,
) -> DuckDBPyRelation: ...
def register(
    view_name: str,
    python_object: typing.Any,
    *,
    connection: duckdb.DuckDBPyConnection | None = None,  # noqa: ANN401
) -> duckdb.DuckDBPyConnection: ...
def register_filesystem(
    filesystem: fsspec.AbstractFileSystem, *, connection: duckdb.DuckDBPyConnection | None = None
) -> None: ...
def remove_function(name: str, *, connection: duckdb.DuckDBPyConnection | None = None) -> duckdb.DuckDBPyConnection: ...
def rollback(*, connection: duckdb.DuckDBPyConnection | None = None) -> duckdb.DuckDBPyConnection: ...
def row_type(
    fields: typing.Any,
    *,
    connection: duckdb.DuckDBPyConnection | None = None,  # noqa: ANN401
) -> duckdb_typing.DuckDBPyType: ...
def rowcount(*, connection: duckdb.DuckDBPyConnection | None = None) -> int: ...
def set_default_connection(connection: duckdb.DuckDBPyConnection) -> None: ...
def sql(
    query: typing.Any,  # noqa: ANN401
    *,
    alias: str = "",
    params: typing.Any = None,  # noqa: ANN401
    connection: duckdb.DuckDBPyConnection | None = None,
) -> DuckDBPyRelation: ...
def sqltype(type_str: str, *, connection: duckdb.DuckDBPyConnection | None = None) -> duckdb_typing.DuckDBPyType: ...
def string_type(
    collation: str = "", *, connection: duckdb.DuckDBPyConnection | None = None
) -> duckdb_typing.DuckDBPyType: ...
def struct_type(
    fields: typing.Any,
    *,
    connection: duckdb.DuckDBPyConnection | None = None,  # noqa: ANN401
) -> duckdb_typing.DuckDBPyType: ...
def table(table_name: str, *, connection: duckdb.DuckDBPyConnection | None = None) -> DuckDBPyRelation: ...
def table_function(
    name: str,
    parameters: typing.Any = None,
    *,
    connection: duckdb.DuckDBPyConnection | None = None,  # noqa: ANN401
) -> DuckDBPyRelation: ...
def tf(*, connection: duckdb.DuckDBPyConnection | None = None) -> dict: ...
def tokenize(query: str) -> list: ...
def torch(*, connection: duckdb.DuckDBPyConnection | None = None) -> dict: ...
def type(type_str: str, *, connection: duckdb.DuckDBPyConnection | None = None) -> duckdb_typing.DuckDBPyType: ...
def union_type(
    members: typing.Any,
    *,
    connection: duckdb.DuckDBPyConnection | None = None,  # noqa: ANN401
) -> duckdb_typing.DuckDBPyType: ...
def unregister(view_name: str, *, connection: duckdb.DuckDBPyConnection | None = None) -> duckdb.DuckDBPyConnection: ...
def unregister_filesystem(name: str, *, connection: duckdb.DuckDBPyConnection | None = None) -> None: ...
def values(*args, connection: duckdb.DuckDBPyConnection | None = None) -> DuckDBPyRelation: ...
def view(view_name: str, *, connection: duckdb.DuckDBPyConnection | None = None) -> DuckDBPyRelation: ...
def write_csv(
    df: pandas.DataFrame,
    filename: str,
    *,
    sep: typing.Any = None,  # noqa: ANN401
    na_rep: typing.Any = None,  # noqa: ANN401
    header: typing.Any = None,  # noqa: ANN401
    quotechar: typing.Any = None,  # noqa: ANN401
    escapechar: typing.Any = None,  # noqa: ANN401
    date_format: typing.Any = None,  # noqa: ANN401
    timestamp_format: typing.Any = None,  # noqa: ANN401
    quoting: typing.Any = None,  # noqa: ANN401
    encoding: typing.Any = None,  # noqa: ANN401
    compression: typing.Any = None,  # noqa: ANN401
    overwrite: typing.Any = None,  # noqa: ANN401
    per_thread_output: typing.Any = None,  # noqa: ANN401
    use_tmp_file: typing.Any = None,  # noqa: ANN401
    partition_by: typing.Any = None,  # noqa: ANN401
    write_partition_columns: typing.Any = None,  # noqa: ANN401
    connection: duckdb.DuckDBPyConnection | None = None,
) -> None: ...

__formatted_python_version__: str = "3.11"
__git_revision__: str = "b8a06e4a22"
__interactive__: bool = False
__jupyter__: bool = False
__standard_vector_size__: int = 2048
__version__: str = "1.4.0"
_clean_default_connection: typing.Any  # value = <capsule object>
apilevel: str = "2.0"
paramstyle: str = "qmark"
threadsafety: int = 1
